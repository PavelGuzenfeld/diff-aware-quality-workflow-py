name: C++ Quality Checks

on:
  workflow_call:
    inputs:
      docker_image:
        type: string
        required: true
        description: 'Docker image with clang-tidy, cppcheck, and compile_commands.json'
      compile_commands_path:
        type: string
        default: 'build'
        description: 'Path to directory containing compile_commands.json (inside container)'
      source_mount:
        type: string
        default: '/workspace/src'
        description: 'Where repo source is mounted inside the container'
      clang_tidy_config:
        type: string
        default: ''
        description: 'Path to .clang-tidy config (empty = use repo default)'
      cppcheck_suppress:
        type: string
        default: ''
        description: 'Path to cppcheck suppressions file'
      cppcheck_includes:
        type: string
        default: ''
        description: 'Space-separated include directories for cppcheck'
      cppcheck_include_file:
        type: string
        default: ''
        description: 'Path to file containing include dirs for cppcheck (one per line)'
      cppcheck_std:
        type: string
        default: 'c++23'
        description: 'C++ standard for cppcheck'
      runner:
        type: string
        default: '"ubuntu-latest"'
        description: 'Runner labels as JSON (e.g., "\"ubuntu-latest\"" or "[\"self-hosted\",\"X64\",\"Linux\"]")'
      file_extensions:
        type: string
        default: 'cpp hpp h cc cxx'
        description: 'Space-separated C++ file extensions to check'
      enforce_doctest:
        type: boolean
        default: false
        description: 'Require doctest instead of gtest in test files'
      test_file_pattern:
        type: string
        default: 'test'
        description: 'Grep pattern to identify test files (matched against path)'
      enable_clang_format:
        type: boolean
        default: false
        description: 'Enable clang-format check on changed files (opt-in)'
      clang_format_config:
        type: string
        default: ''
        description: 'Path to .clang-format config (empty = use repo default)'
      source_setup:
        type: string
        default: ''
        description: 'Shell command to source before running tools (e.g., source /opt/ros/humble/install/setup.bash)'
      enable_file_naming:
        type: boolean
        default: false
        description: 'Enable file/directory naming convention check (snake_case enforcement, opt-in)'
      file_naming_exceptions:
        type: string
        default: ''
        description: 'Path to file with additional naming exception regexes (one per line)'
      file_naming_allowed_prefixes:
        type: string
        default: '_'
        description: 'Space-separated allowed prefixes for file/dir names (e.g., _ for pybind11 _bindings.so)'
      ban_cout:
        type: boolean
        default: false
        description: 'Ban std::cout/cerr/clog and printf family in non-test source files (opt-in)'
      ban_new:
        type: boolean
        default: false
        description: 'Ban raw new/delete in non-test source files (opt-in)'
      clang_tidy_jobs:
        type: number
        default: 4
        description: 'Parallel clang-tidy jobs inside Docker container'
      exclude_file:
        type: string
        default: ''
        description: 'Path to file listing excluded paths (one per line, # comments)'
      enable_flawfinder:
        type: boolean
        default: false
        description: 'Enable flawfinder CWE lexical scan (opt-in)'
      flawfinder_min_level:
        type: number
        default: 2
        description: 'Minimum flawfinder finding level (1-5)'
      enable_sarif:
        type: boolean
        default: false
        description: 'Upload SARIF to GitHub Security tab (requires security-events: write)'
      pre_analysis_script:
        type: string
        default: ''
        description: 'Script path (in repo) to run inside Docker before analysis (build compile_commands.json, etc.)'
      build_cache_key:
        type: string
        default: ''
        description: 'Cache key for build artifacts (empty = no caching)'
      build_cache_paths:
        type: string
        default: 'build install'
        description: 'Space-separated paths to cache'
      checkout_submodules:
        type: string
        default: 'false'
        description: 'Pass to actions/checkout submodules parameter (false, true, recursive)'
      enable_sanitizers:
        type: boolean
        default: false
        description: 'Enable ASAN/UBSAN test job'
      sanitizer_script:
        type: string
        default: ''
        description: 'Script to build+test with sanitizers (in repo). If empty, uses default colcon flow.'
      sanitizer_suppressions:
        type: string
        default: ''
        description: 'Path to LSAN suppressions file (in repo)'
      sanitizer_packages:
        type: string
        default: ''
        description: 'Space-separated packages to test (empty = all)'
      enable_iwyu:
        type: boolean
        default: false
        description: 'Enable Include-What-You-Use analysis (opt-in, non-blocking)'
      iwyu_script:
        type: string
        default: ''
        description: 'Script to run IWYU analysis (in repo). If empty, uses default flow.'
      iwyu_mapping_file:
        type: string
        default: ''
        description: 'Path to IWYU mapping file (.imp) in repo'
      enable_tsan:
        type: boolean
        default: false
        description: 'Enable ThreadSanitizer (TSAN) test job (mutually exclusive with ASAN)'
      tsan_script:
        type: string
        default: ''
        description: 'Script to build+test with TSAN (in repo). If empty, uses default colcon flow.'
      tsan_suppressions:
        type: string
        default: ''
        description: 'Path to TSAN suppressions file (in repo)'
      tsan_packages:
        type: string
        default: ''
        description: 'Space-separated packages to test with TSAN (empty = all)'
      enable_coverage:
        type: boolean
        default: false
        description: 'Enable gcov/lcov test coverage reporting (opt-in, non-blocking)'
      coverage_script:
        type: string
        default: ''
        description: 'Script to build+test with coverage and collect lcov (in repo). If empty, uses default flow.'
      coverage_packages:
        type: string
        default: ''
        description: 'Space-separated packages to measure coverage (empty = all)'
      coverage_threshold:
        type: string
        default: '0'
        description: 'Minimum overall line coverage % (0 = no threshold, job always passes)'
      coverage_diff_threshold:
        type: string
        default: '0'
        description: 'Minimum line coverage % for changed lines via diff-cover (0 = disabled)'
      coverage_diff_report:
        type: boolean
        default: false
        description: 'Generate diff-cover markdown report as artifact'
      select_jobs:
        type: string
        default: 'all'
        description: 'Comma-separated jobs to run (all, clang-tidy, cppcheck, coverage, tsan, sanitizers, iwyu, clang-format, doctest, file-naming, cout-ban, new-delete-ban, flawfinder)'
      base_ref:
        type: string
        default: ''
        description: 'Base branch for diff (fallback when github.base_ref is empty, e.g. workflow_dispatch)'
      enable_clang_tidy:
        type: boolean
        default: true
        description: 'Enable clang-tidy analysis (on by default for backward compat)'
      enable_cppcheck:
        type: boolean
        default: true
        description: 'Enable cppcheck analysis (on by default for backward compat)'
      cppcheck_inconclusive:
        type: boolean
        default: false
        description: 'Enable cppcheck --inconclusive mode (may produce false positives)'
      cppcheck_strict:
        type: boolean
        default: false
        description: 'Use --error-exitcode=1 for native cppcheck error handling'
      enable_shellcheck:
        type: boolean
        default: false
        description: 'DEPRECATED: moved to infra-lint.yml. Kept for backward compatibility — ignored.'
      shellcheck_severity:
        type: string
        default: 'warning'
        description: 'DEPRECATED: moved to infra-lint.yml. Kept for backward compatibility — ignored.'
      enable_hadolint:
        type: boolean
        default: false
        description: 'DEPRECATED: moved to infra-lint.yml. Kept for backward compatibility — ignored.'
      hadolint_config:
        type: string
        default: ''
        description: 'DEPRECATED: moved to infra-lint.yml. Kept for backward compatibility — ignored.'

permissions:
  actions: read
  contents: read
  packages: read
  pull-requests: write
  security-events: write

jobs:
  verify-toolchain:
    name: Verify Toolchain
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Verify Docker image tools
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi

          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            -e ENABLE_TIDY="${{ inputs.enable_clang_tidy }}" \
            -e ENABLE_CPPCHECK="${{ inputs.enable_cppcheck }}" \
            -e ENABLE_FORMAT="${{ inputs.enable_clang_format }}" \
            -e ENABLE_IWYU="${{ inputs.enable_iwyu }}" \
            -e ENABLE_SANITIZERS="${{ inputs.enable_sanitizers }}" \
            -e ENABLE_TSAN="${{ inputs.enable_tsan }}" \
            -e ENABLE_COVERAGE="${{ inputs.enable_coverage }}" \
            -e PRE_SCRIPT="${{ inputs.pre_analysis_script }}" \
            -e CDB_PATH="${{ inputs.compile_commands_path }}/compile_commands.json" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}"'
              MISSING=""
              VERSIONS=""

              check_tool() {
                local name="$1" cmd="$2" version_flag="$3"
                if command -v "$cmd" &>/dev/null; then
                  VER=$("$cmd" $version_flag 2>&1 | head -1 || echo "unknown")
                  VERSIONS="${VERSIONS}  ${name}: ${VER}\n"
                else
                  MISSING="${MISSING}  - ${name} (${cmd})\n"
                fi
              }

              # Per-job tool checks (only verify tools needed by enabled jobs)
              [ "$ENABLE_TIDY" = "true" ] && check_tool "clang-tidy" "clang-tidy" "--version"
              [ "$ENABLE_CPPCHECK" = "true" ] && check_tool "cppcheck" "cppcheck" "--version"
              [ "$ENABLE_FORMAT" = "true" ] && check_tool "clang-format" "clang-format" "--version"
              [ "$ENABLE_IWYU" = "true" ] && check_tool "IWYU" "include-what-you-use" "--version"

              # cmake needed for builds (sanitizers, tsan, coverage) and compile_commands
              if [ "$ENABLE_TIDY" = "true" ] || [ "$ENABLE_SANITIZERS" = "true" ] || \
                 [ "$ENABLE_TSAN" = "true" ] || [ "$ENABLE_COVERAGE" = "true" ] || \
                 [ "$ENABLE_IWYU" = "true" ]; then
                check_tool "cmake" "cmake" "--version"
              fi

              # compile_commands.json needed for clang-tidy and iwyu
              if [ "$ENABLE_TIDY" = "true" ] || [ "$ENABLE_IWYU" = "true" ]; then
                if [ -z "$PRE_SCRIPT" ]; then
                  if [ -f "$CDB_PATH" ]; then
                    VERSIONS="${VERSIONS}  compile_commands.json: found at ${CDB_PATH}\n"
                  else
                    MISSING="${MISSING}  - compile_commands.json at ${CDB_PATH}\n"
                  fi
                else
                  VERSIONS="${VERSIONS}  compile_commands.json: will be generated by pre_analysis_script\n"
                fi
              fi

              echo "=== Toolchain Versions ==="
              printf "%b" "$VERSIONS"

              if [ -n "$MISSING" ]; then
                echo ""
                echo "ERROR: Missing required tools in Docker image:"
                printf "%b" "$MISSING"
                echo ""
                echo "Ensure your Docker image includes all required tools before running analysis."
                exit 1
              fi

              echo ""
              echo "All required tools verified."
            '

  clang-tidy:
    name: clang-tidy
    needs: [verify-toolchain]
    if: inputs.enable_clang_tidy && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'clang-tidy'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Get changed C++ files
        id: changed
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- | grep -E "$EXT_PATTERN" || true)
          if [ -z "$FILES" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "No C++ files changed."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "$FILES" > /tmp/changed_cpp_files.txt
            echo "Found $(echo "$FILES" | wc -l) changed file(s)."
          fi

      - name: Filter excluded paths
        if: steps.changed.outputs.skip == 'false' && inputs.exclude_file != ''
        run: |
          EXCLUDE_FILE="${{ inputs.exclude_file }}"
          FILE_LIST="/tmp/changed_cpp_files.txt"
          if [ -f "$EXCLUDE_FILE" ] && [ -f "$FILE_LIST" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "$EXCLUDE_FILE"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              TEMP=$(mktemp)
              while IFS= read -r fp || [ -n "$fp" ]; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do
                  [[ "$fp" == "$p"* ]] && excl=true && break
                done
                [ "$excl" = false ] && echo "$fp"
              done < "$FILE_LIST" > "$TEMP"
              mv "$TEMP" "$FILE_LIST"
              echo "After exclusion filter: $(wc -l < "$FILE_LIST") file(s) remaining."
            fi
            if [ ! -s "$FILE_LIST" ]; then
              echo "All changed files are in excluded paths."
              echo "skip=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Prepare cache paths
        if: steps.changed.outputs.skip == 'false' && inputs.build_cache_key != ''
        id: cache-paths
        run: |
          {
            echo "paths<<EOF"
            echo "${{ inputs.build_cache_paths }}" | tr ' ' '\n'
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Restore build cache
        if: steps.changed.outputs.skip == 'false' && inputs.build_cache_key != ''
        uses: actions/cache@v5
        with:
          path: ${{ steps.cache-paths.outputs.paths }}
          key: ${{ inputs.build_cache_key }}
          restore-keys: |
            ${{ inputs.build_cache_key }}-

      - name: Run pre-analysis script
        if: steps.changed.outputs.skip == 'false' && inputs.pre_analysis_script != ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}bash ${{ inputs.pre_analysis_script }}"

      - name: Run clang-tidy in Docker (batch)
        if: steps.changed.outputs.skip == 'false'
        id: clang-tidy
        run: |
          CONFIG_ARG=""
          if [ -n "${{ inputs.clang_tidy_config }}" ]; then
            CONFIG_ARG="--config-file=${{ inputs.clang_tidy_config }}"
          fi

          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi

          JOBS=${{ inputs.clang_tidy_jobs }}

          # Copy file list into workspace for Docker access
          cp /tmp/changed_cpp_files.txt changed_files.txt

          # Single container, parallel analysis via xargs
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}cat changed_files.txt | \
              xargs -P${JOBS} -I{} clang-tidy -p ${{ inputs.compile_commands_path }} $CONFIG_ARG {} 2>&1" \
            | tee /tmp/clang_tidy_output.txt || true

          # Count findings — exclude clang-diagnostic-* (GCC/Clang differences)
          # Note: grep -c outputs "0" AND exits non-zero when no matches,
          # so "|| echo 0" would produce "0\n0" in $().  Use "|| true" instead.
          WARNS=$(grep -c "warning:" /tmp/clang_tidy_output.txt 2>/dev/null || true)
          [ -z "$WARNS" ] && WARNS=0
          ALL_ERRS=$(grep -c "error:" /tmp/clang_tidy_output.txt 2>/dev/null || true)
          [ -z "$ALL_ERRS" ] && ALL_ERRS=0
          DIAG_ERRS=$(grep -c "clang-diagnostic-" /tmp/clang_tidy_output.txt 2>/dev/null || true)
          [ -z "$DIAG_ERRS" ] && DIAG_ERRS=0
          TIDY_ERRS=$((ALL_ERRS - DIAG_ERRS))
          [ "$TIDY_ERRS" -lt 0 ] && TIDY_ERRS=0

          echo "=== Summary: ${WARNS} warnings, ${TIDY_ERRS} tidy errors (${DIAG_ERRS} diagnostic errors excluded) ==="

          # Emit GitHub annotations (first 50)
          grep -E '^.+:[0-9]+:[0-9]+: (warning|error):' /tmp/clang_tidy_output.txt | head -50 | while IFS= read -r line; do
            ann_file=$(echo "$line" | cut -d: -f1)
            ann_line=$(echo "$line" | cut -d: -f2)
            ann_col=$(echo "$line" | cut -d: -f3)
            severity=$(echo "$line" | cut -d: -f4 | tr -d ' ')
            message=$(echo "$line" | cut -d: -f5-)
            if [ "$severity" = "error" ]; then
              echo "::error file=${ann_file},line=${ann_line},col=${ann_col}::${message}"
            else
              echo "::warning file=${ann_file},line=${ann_line},col=${ann_col}::${message}"
            fi
          done

          echo "warnings=$WARNS" >> $GITHUB_OUTPUT
          echo "errors=$TIDY_ERRS" >> $GITHUB_OUTPUT

          if [ "$TIDY_ERRS" -gt 0 ] || [ "$WARNS" -gt 0 ]; then
            echo "clang-tidy: $TIDY_ERRS error(s) and $WARNS warning(s) found."
            exit 1
          fi

  cppcheck:
    name: cppcheck
    needs: [verify-toolchain]
    if: inputs.enable_cppcheck && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'cppcheck'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Get changed C++ files
        id: changed
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- | grep -E "$EXT_PATTERN" || true)
          if [ -z "$FILES" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "No C++ files changed."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "$FILES" > /tmp/changed_cpp_files.txt
            echo "Found $(echo "$FILES" | wc -l) changed file(s)."
          fi

      - name: Filter excluded paths
        if: steps.changed.outputs.skip == 'false' && inputs.exclude_file != ''
        run: |
          EXCLUDE_FILE="${{ inputs.exclude_file }}"
          FILE_LIST="/tmp/changed_cpp_files.txt"
          if [ -f "$EXCLUDE_FILE" ] && [ -f "$FILE_LIST" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "$EXCLUDE_FILE"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              TEMP=$(mktemp)
              while IFS= read -r fp || [ -n "$fp" ]; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do
                  [[ "$fp" == "$p"* ]] && excl=true && break
                done
                [ "$excl" = false ] && echo "$fp"
              done < "$FILE_LIST" > "$TEMP"
              mv "$TEMP" "$FILE_LIST"
              echo "After exclusion filter: $(wc -l < "$FILE_LIST") file(s) remaining."
            fi
            if [ ! -s "$FILE_LIST" ]; then
              echo "All changed files are in excluded paths."
              echo "skip=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Run cppcheck in Docker
        if: steps.changed.outputs.skip == 'false'
        id: cppcheck
        run: |
          CPPCHECK_ARGS="--enable=warning,style,performance,portability --template=gcc --std=${{ inputs.cppcheck_std }} --inline-suppr"

          if [ "${{ inputs.cppcheck_inconclusive }}" = "true" ]; then
            CPPCHECK_ARGS="$CPPCHECK_ARGS --inconclusive"
          fi

          if [ "${{ inputs.cppcheck_strict }}" = "true" ]; then
            CPPCHECK_ARGS="$CPPCHECK_ARGS --error-exitcode=1"
          else
            CPPCHECK_ARGS="$CPPCHECK_ARGS --error-exitcode=0"
          fi

          if [ -n "${{ inputs.cppcheck_suppress }}" ] && [ -f "${{ inputs.cppcheck_suppress }}" ]; then
            CPPCHECK_ARGS="$CPPCHECK_ARGS --suppressions-list=${{ inputs.cppcheck_suppress }}"
          fi

          INCLUDE_ARGS=""
          if [ -n "${{ inputs.cppcheck_includes }}" ]; then
            for dir in ${{ inputs.cppcheck_includes }}; do
              INCLUDE_ARGS="$INCLUDE_ARGS -I $dir"
            done
          fi

          # Read include dirs from file if provided
          if [ -n "${{ inputs.cppcheck_include_file }}" ] && [ -f "${{ inputs.cppcheck_include_file }}" ]; then
            while IFS= read -r dir || [ -n "$dir" ]; do
              dir=$(echo "$dir" | xargs)
              [ -z "$dir" ] && continue
              [[ "$dir" == \#* ]] && continue
              INCLUDE_ARGS="$INCLUDE_ARGS -I $dir"
            done < "${{ inputs.cppcheck_include_file }}"
          fi

          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi

          FILES=$(cat /tmp/changed_cpp_files.txt | tr '\n' ' ')

          CPPCHECK_EXIT=0
          OUTPUT=$(docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}cppcheck $CPPCHECK_ARGS $INCLUDE_ARGS $FILES" 2>&1) || CPPCHECK_EXIT=$?

          ERRORS=0
          if [ -n "$OUTPUT" ]; then
            echo "$OUTPUT"
            echo "$OUTPUT" > /tmp/cppcheck_output.txt

            # Emit GitHub annotations
            echo "$OUTPUT" | grep -E '^.+:[0-9]+:.*(error|warning|style|performance|portability):' | while IFS= read -r line; do
              ann_file=$(echo "$line" | cut -d: -f1)
              ann_line=$(echo "$line" | cut -d: -f2)
              severity=$(echo "$line" | cut -d: -f3 | tr -d ' ')
              message=$(echo "$line" | cut -d: -f4-)
              case "$severity" in
                error) echo "::error file=${ann_file},line=${ann_line}::${message}" ;;
                *)     echo "::warning file=${ann_file},line=${ann_line}::${message}" ;;
              esac
            done

            ERRORS=$(echo "$OUTPUT" | grep -cE '^.+:[0-9]+:.*error:' || true)
          fi

          echo "errors=$ERRORS" >> $GITHUB_OUTPUT

          if [ "${{ inputs.cppcheck_strict }}" = "true" ] && [ "$CPPCHECK_EXIT" -ne 0 ]; then
            echo "cppcheck: exited with code $CPPCHECK_EXIT (strict mode)."
            exit 1
          elif [ "$ERRORS" -gt 0 ]; then
            echo "cppcheck: $ERRORS error(s) found."
            exit 1
          fi

  clang-format:
    name: clang-format
    needs: [verify-toolchain]
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.enable_clang_format && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'clang-format'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Get changed C++ files
        id: changed
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- | grep -E "$EXT_PATTERN" || true)
          if [ -z "$FILES" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "No C++ files changed."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "$FILES" > /tmp/changed_cpp_files.txt
            echo "Found $(echo "$FILES" | wc -l) changed file(s)."
          fi

      - name: Filter excluded paths
        if: steps.changed.outputs.skip == 'false' && inputs.exclude_file != ''
        run: |
          EXCLUDE_FILE="${{ inputs.exclude_file }}"
          FILE_LIST="/tmp/changed_cpp_files.txt"
          if [ -f "$EXCLUDE_FILE" ] && [ -f "$FILE_LIST" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "$EXCLUDE_FILE"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              TEMP=$(mktemp)
              while IFS= read -r fp || [ -n "$fp" ]; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do
                  [[ "$fp" == "$p"* ]] && excl=true && break
                done
                [ "$excl" = false ] && echo "$fp"
              done < "$FILE_LIST" > "$TEMP"
              mv "$TEMP" "$FILE_LIST"
              echo "After exclusion filter: $(wc -l < "$FILE_LIST") file(s) remaining."
            fi
            if [ ! -s "$FILE_LIST" ]; then
              echo "All changed files are in excluded paths."
              echo "skip=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Prepare clang-format container
        if: steps.changed.outputs.skip == 'false' && inputs.docker_image != ''
        run: |
          docker run -d --name cf-container \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" sleep infinity
          # Install clang-format if not already in image
          docker exec cf-container bash -c "
            if ! command -v clang-format &>/dev/null; then
              echo 'clang-format not found, installing...'
              apt-get update -qq && apt-get install -y -qq clang-format 2>/dev/null || {
                wget -qO- https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - 2>/dev/null
                . /etc/os-release
                echo \"deb http://apt.llvm.org/\${VERSION_CODENAME}/ llvm-toolchain-\${VERSION_CODENAME} main\" \
                  > /etc/apt/sources.list.d/llvm.list
                apt-get update -qq && apt-get install -y -qq clang-format
              }
            fi
            clang-format --version
          "

      - name: Run clang-format in Docker
        if: steps.changed.outputs.skip == 'false'
        id: clang-format
        run: |
          FORMAT_ARGS="--dry-run --Werror"
          if [ -n "${{ inputs.clang_format_config }}" ]; then
            FORMAT_ARGS="$FORMAT_ARGS --style=file:${{ inputs.clang_format_config }}"
          fi

          VIOLATIONS=0
          while IFS= read -r file; do
            [ -f "$file" ] || continue
            OUTPUT=$(docker exec cf-container clang-format $FORMAT_ARGS "$file" 2>&1 || true)

            if [ -n "$OUTPUT" ]; then
              echo "$OUTPUT"
              # Emit GitHub annotations
              echo "$OUTPUT" | grep -E '^.+:[0-9]+:[0-9]+:' | while IFS= read -r line; do
                ann_file=$(echo "$line" | cut -d: -f1)
                ann_line=$(echo "$line" | cut -d: -f2)
                ann_col=$(echo "$line" | cut -d: -f3)
                message=$(echo "$line" | cut -d: -f4-)
                echo "::error file=${ann_file},line=${ann_line},col=${ann_col}::clang-format:${message}"
              done
              VIOLATIONS=$((VIOLATIONS + 1))
            fi
          done < /tmp/changed_cpp_files.txt

          echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT

          if [ "$VIOLATIONS" -gt 0 ]; then
            echo "clang-format: $VIOLATIONS file(s) with violations."
            exit 1
          fi

      - name: Cleanup clang-format container
        if: always()
        run: docker rm -f cf-container 2>/dev/null || true

  doctest-enforce:
    name: doctest enforcement
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.enforce_doctest && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'doctest'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check changed test files for banned frameworks
        id: check
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- \
            | grep -E "$EXT_PATTERN" \
            | grep -iE "${{ inputs.test_file_pattern }}" || true)

          # Apply exclusion filter
          if [ -n "$FILES" ] && [ -n "${{ inputs.exclude_file }}" ] && [ -f "${{ inputs.exclude_file }}" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "${{ inputs.exclude_file }}"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              FILTERED=""
              while IFS= read -r fp; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do [[ "$fp" == "$p"* ]] && excl=true && break; done
                [ "$excl" = false ] && FILTERED="${FILTERED}${fp}"$'\n'
              done <<< "$FILES"
              FILES=$(echo "$FILTERED" | sed '/^$/d')
            fi
          fi

          if [ -z "$FILES" ]; then
            echo "No test files changed — skipping doctest check."
            echo "violations=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Scanning $(echo "$FILES" | wc -l) changed test file(s) for gtest/benchmark usage..."

          # Patterns that indicate gtest instead of doctest
          GTEST_PATTERNS='TEST\(|TEST_F\(|TEST_P\(|TYPED_TEST\(|EXPECT_EQ\(|EXPECT_NE\(|EXPECT_TRUE\(|EXPECT_FALSE\(|EXPECT_STREQ\(|EXPECT_THROW\(|EXPECT_NO_THROW\(|EXPECT_NEAR\(|EXPECT_LT\(|EXPECT_LE\(|EXPECT_GT\(|EXPECT_GE\(|EXPECT_THAT\(|ASSERT_EQ\(|ASSERT_NE\(|ASSERT_TRUE\(|ASSERT_FALSE\(|ASSERT_STREQ\(|ASSERT_THROW\(|ASSERT_NO_THROW\(|ASSERT_NEAR\(|ASSERT_LT\(|ASSERT_LE\(|ASSERT_GT\(|ASSERT_GE\(|ASSERT_THAT\(|ASSERT_DEATH\(|#include\s*[<"]gtest/|#include\s*[<"]gmock/'

          # Patterns that indicate Google Benchmark instead of nanobench
          GBENCH_PATTERNS='benchmark::State|BENCHMARK\(|BENCHMARK_DEFINE_F\(|BENCHMARK_REGISTER_F\(|#include\s*[<"]benchmark/benchmark\.h[>"]'

          VIOLATIONS=0
          while IFS= read -r file; do
            [ -f "$file" ] || continue

            # Check for gtest
            MATCHES=$(grep -nE "$GTEST_PATTERNS" "$file" || true)
            if [ -n "$MATCHES" ]; then
              echo ""
              echo "--- $file (gtest) ---"
              echo "$MATCHES"
              echo "$MATCHES" | while IFS= read -r match; do
                line_num=$(echo "$match" | cut -d: -f1)
                content=$(echo "$match" | cut -d: -f2-)
                echo "::error file=${file},line=${line_num}::Use doctest instead of gtest: ${content}"
              done
              VIOLATIONS=$((VIOLATIONS + $(echo "$MATCHES" | wc -l)))
            fi

            # Check for Google Benchmark
            BMATCHES=$(grep -nE "$GBENCH_PATTERNS" "$file" || true)
            if [ -n "$BMATCHES" ]; then
              echo ""
              echo "--- $file (google benchmark) ---"
              echo "$BMATCHES"
              echo "$BMATCHES" | while IFS= read -r match; do
                line_num=$(echo "$match" | cut -d: -f1)
                content=$(echo "$match" | cut -d: -f2-)
                echo "::error file=${file},line=${line_num}::Use nanobench instead of Google Benchmark: ${content}"
              done
              VIOLATIONS=$((VIOLATIONS + $(echo "$BMATCHES" | wc -l)))
            fi
          done <<< "$FILES"

          echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT

          if [ "$VIOLATIONS" -gt 0 ]; then
            echo ""
            echo "doctest-enforce: $VIOLATIONS violation(s) found. Use doctest (TEST_CASE/CHECK/REQUIRE) and nanobench."
            exit 1
          fi

          echo "doctest-enforce: all changed test files use approved frameworks."

  file-naming:
    name: file naming
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.enable_file_naming && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'file-naming'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check file naming conventions
        id: naming
        run: |
          ALLOWED_PREFIXES="${{ inputs.file_naming_allowed_prefixes }}"
          EXCEPTIONS_FILE="${{ inputs.file_naming_exceptions }}"

          # Built-in exception filenames (exact match)
          BUILTIN_EXEMPT_FILES=(
              "CMakeLists.txt" "Dockerfile" "README.md" "CLAUDE.md"
              "CHANGELOG.md" "CONTRIBUTING.md" "LICENSE" "Makefile"
              "Doxyfile" "package.xml" "pyproject.toml" "setup.py"
              "setup.cfg" "Cargo.toml" "Cargo.lock"
          )

          # Built-in exception patterns (regex, matched against filename)
          BUILTIN_EXEMPT_PATTERNS=(
              '^requirements.*\.txt$'
              '^\.'
              '^__init__\.py$'
              '^__main__\.py$'
              '^__pycache__$'
              '^py\.typed$'
              '^[A-Z][A-Z_-]*\.md$'
          )

          SNAKE_CASE='^[a-z][a-z0-9_]*$'

          # Load user exceptions
          USER_EXCEPTIONS=()
          if [ -n "$EXCEPTIONS_FILE" ] && [ -f "$EXCEPTIONS_FILE" ]; then
              while IFS= read -r line || [ -n "$line" ]; do
                  line=$(echo "$line" | xargs)
                  [ -z "$line" ] && continue
                  [[ "$line" == \#* ]] && continue
                  USER_EXCEPTIONS+=("$line")
              done < "$EXCEPTIONS_FILE"
          fi

          CHANGED_FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- || true)

          # Apply exclusion filter
          if [ -n "$CHANGED_FILES" ] && [ -n "${{ inputs.exclude_file }}" ] && [ -f "${{ inputs.exclude_file }}" ]; then
              PATTERNS=()
              while IFS= read -r line || [ -n "$line" ]; do
                  line="${line%%#*}"; line="$(echo "$line" | xargs)"
                  [ -z "$line" ] && continue
                  PATTERNS+=("$line")
              done < "${{ inputs.exclude_file }}"
              if [ ${#PATTERNS[@]} -gt 0 ]; then
                  FILTERED=""
                  while IFS= read -r fp; do
                      [ -z "$fp" ] && continue
                      excl=false
                      for p in "${PATTERNS[@]}"; do [[ "$fp" == "$p"* ]] && excl=true && break; done
                      [ "$excl" = false ] && FILTERED="${FILTERED}${fp}"$'\n'
                  done <<< "$CHANGED_FILES"
                  CHANGED_FILES=$(echo "$FILTERED" | sed '/^$/d')
              fi
          fi

          if [ -z "$CHANGED_FILES" ]; then
              echo "No files changed — skipping file naming check."
              echo "violations=0" >> $GITHUB_OUTPUT
              exit 0
          fi

          FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)
          echo "Checking file naming conventions on $FILE_COUNT changed file(s)..."

          is_exempt_filename() {
              local name="$1"
              for exempt in "${BUILTIN_EXEMPT_FILES[@]}"; do
                  [ "$name" = "$exempt" ] && return 0
              done
              return 1
          }

          is_exempt_pattern() {
              local name="$1"
              for pattern in "${BUILTIN_EXEMPT_PATTERNS[@]}"; do
                  echo "$name" | grep -qE "$pattern" && return 0
              done
              return 1
          }

          is_user_exception() {
              local name="$1"
              for pattern in "${USER_EXCEPTIONS[@]}"; do
                  echo "$name" | grep -qE "$pattern" && return 0
              done
              return 1
          }

          is_snake_case() {
              local name="$1"
              echo "$name" | grep -qE "$SNAKE_CASE" && return 0
              for prefix in $ALLOWED_PREFIXES; do
                  if [[ "$name" == "${prefix}"* ]]; then
                      local stripped="${name#$prefix}"
                      [ -n "$stripped" ] && echo "$stripped" | grep -qE "$SNAKE_CASE" && return 0
                  fi
              done
              return 1
          }

          VIOLATIONS=0
          while IFS= read -r filepath; do
              IFS='/' read -ra SEGMENTS <<< "$filepath"
              SEGMENT_COUNT=${#SEGMENTS[@]}
              for i in "${!SEGMENTS[@]}"; do
                  segment="${SEGMENTS[$i]}"
                  is_last=$(( i == SEGMENT_COUNT - 1 ))

                  # Skip dotdirs and their children
                  if echo "$segment" | grep -qE '^\.' ; then
                      break
                  fi

                  if [ "$is_last" -eq 1 ]; then
                      is_exempt_filename "$segment" && continue
                      is_exempt_pattern "$segment" && continue
                      [ ${#USER_EXCEPTIONS[@]} -gt 0 ] && is_user_exception "$segment" && continue
                      name_without_ext="${segment%.*}"
                  else
                      is_exempt_pattern "$segment" && continue
                      [ ${#USER_EXCEPTIONS[@]} -gt 0 ] && is_user_exception "$segment" && continue
                      name_without_ext="$segment"
                  fi

                  if ! is_snake_case "$name_without_ext"; then
                      echo "::error file=${filepath}::File naming violation: '${segment}' is not snake_case (path: ${filepath})"
                      VIOLATIONS=$((VIOLATIONS + 1))
                      break
                  fi
              done
          done <<< "$CHANGED_FILES"

          echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT

          if [ "$VIOLATIONS" -gt 0 ]; then
              echo "file-naming: $VIOLATIONS violation(s) found."
              exit 1
          fi

          echo "file-naming: all changed files follow snake_case convention."

  cout-ban:
    name: cout/printf ban
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.ban_cout && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'cout-ban'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check changed source files for banned I/O
        id: check
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- \
            | grep -E "$EXT_PATTERN" \
            | grep -viE "${{ inputs.test_file_pattern }}" || true)

          # Apply exclusion filter
          if [ -n "$FILES" ] && [ -n "${{ inputs.exclude_file }}" ] && [ -f "${{ inputs.exclude_file }}" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "${{ inputs.exclude_file }}"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              FILTERED=""
              while IFS= read -r fp; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do [[ "$fp" == "$p"* ]] && excl=true && break; done
                [ "$excl" = false ] && FILTERED="${FILTERED}${fp}"$'\n'
              done <<< "$FILES"
              FILES=$(echo "$FILTERED" | sed '/^$/d')
            fi
          fi

          if [ -z "$FILES" ]; then
            echo "No non-test C++ files changed — skipping cout ban check."
            echo "violations=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Scanning $(echo "$FILES" | wc -l) changed source file(s) for banned I/O..."

          BANNED_PATTERNS='std::cout|std::cerr|std::clog|printf\(|fprintf\(|puts\('

          VIOLATIONS=0
          while IFS= read -r file; do
            [ -f "$file" ] || continue
            # Filter out comment lines (// and block comment continuations *)
            MATCHES=$(grep -nE "$BANNED_PATTERNS" "$file" \
              | grep -vE '^[0-9]+:\s*//' \
              | grep -vE '^[0-9]+:\s*\*' || true)
            if [ -n "$MATCHES" ]; then
              echo ""
              echo "--- $file ---"
              echo "$MATCHES"
              echo "$MATCHES" | while IFS= read -r match; do
                line_num=$(echo "$match" | cut -d: -f1)
                content=$(echo "$match" | cut -d: -f2-)
                echo "::error file=${file},line=${line_num}::Banned I/O call (use structured logging): ${content}"
              done
              VIOLATIONS=$((VIOLATIONS + $(echo "$MATCHES" | wc -l)))
            fi
          done <<< "$FILES"

          echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT

          if [ "$VIOLATIONS" -gt 0 ]; then
            echo ""
            echo "cout-ban: $VIOLATIONS violation(s) found. Use a structured logger instead of cout/printf."
            exit 1
          fi

          echo "cout-ban: no violations found."

  new-delete-ban:
    name: new/delete ban
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.ban_new && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'new-delete-ban'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check changed source files for raw new/delete
        id: check
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- \
            | grep -E "$EXT_PATTERN" \
            | grep -viE "${{ inputs.test_file_pattern }}" || true)

          # Apply exclusion filter
          if [ -n "$FILES" ] && [ -n "${{ inputs.exclude_file }}" ] && [ -f "${{ inputs.exclude_file }}" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "${{ inputs.exclude_file }}"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              FILTERED=""
              while IFS= read -r fp; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do [[ "$fp" == "$p"* ]] && excl=true && break; done
                [ "$excl" = false ] && FILTERED="${FILTERED}${fp}"$'\n'
              done <<< "$FILES"
              FILES=$(echo "$FILTERED" | sed '/^$/d')
            fi
          fi

          if [ -z "$FILES" ]; then
            echo "No non-test C++ files changed — skipping new/delete ban check."
            echo "violations=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Scanning $(echo "$FILES" | wc -l) changed source file(s) for raw new/delete..."

          # Match raw new/delete but not make_unique/make_shared/placement new/operator new
          NEW_PATTERN='\bnew\s+[A-Z_a-z]'
          DELETE_PATTERN='\bdelete(\s|\[)'

          VIOLATIONS=0
          while IFS= read -r file; do
            [ -f "$file" ] || continue

            # Filter out: smart pointers, operator overloads, placement new, includes,
            # comment lines (// and leading *), inline block comments (/* ... */),
            # and string/log literals containing "new"
            MATCHES=$(grep -nE "$NEW_PATTERN|$DELETE_PATTERN" "$file" \
              | grep -vE 'make_unique|make_shared|make_obj|operator\s+(new|delete)|placement|#\s*include' \
              | grep -vE '^\s*[0-9]+:\s*//' \
              | grep -vE '^\s*[0-9]+:\s*\*' \
              | grep -vE '/\*.*\bnew\b.*\*/' \
              | grep -vE '(INFO|WARN|ERROR|DEBUG|LOG|RCLCPP_|SPDLOG_|fmt::)\s*\(' || true)

            if [ -n "$MATCHES" ]; then
              echo ""
              echo "--- $file ---"
              echo "$MATCHES"
              echo "$MATCHES" | while IFS= read -r match; do
                line_num=$(echo "$match" | cut -d: -f1)
                content=$(echo "$match" | cut -d: -f2-)
                echo "::error file=${file},line=${line_num}::Raw new/delete found (use std::make_unique/make_shared): ${content}"
              done
              VIOLATIONS=$((VIOLATIONS + $(echo "$MATCHES" | wc -l)))
            fi
          done <<< "$FILES"

          echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT

          if [ "$VIOLATIONS" -gt 0 ]; then
            echo ""
            echo "new-delete-ban: $VIOLATIONS violation(s) found. Use std::make_unique or std::make_shared instead."
            exit 1
          fi

          echo "new-delete-ban: no violations found."

  flawfinder:
    name: flawfinder
    runs-on: ${{ fromJSON(inputs.runner) }}
    if: inputs.enable_flawfinder && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'flawfinder'))
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed C++ files
        id: changed
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- | grep -E "$EXT_PATTERN" || true)
          if [ -z "$FILES" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "No C++ files changed."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "$FILES" > /tmp/changed_cpp_files.txt
            echo "Found $(echo "$FILES" | wc -l) changed file(s)."
          fi

      - name: Filter excluded paths
        if: steps.changed.outputs.skip == 'false' && inputs.exclude_file != ''
        run: |
          EXCLUDE_FILE="${{ inputs.exclude_file }}"
          FILE_LIST="/tmp/changed_cpp_files.txt"
          if [ -f "$EXCLUDE_FILE" ] && [ -f "$FILE_LIST" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "$EXCLUDE_FILE"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              TEMP=$(mktemp)
              while IFS= read -r fp || [ -n "$fp" ]; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do
                  [[ "$fp" == "$p"* ]] && excl=true && break
                done
                [ "$excl" = false ] && echo "$fp"
              done < "$FILE_LIST" > "$TEMP"
              mv "$TEMP" "$FILE_LIST"
              echo "After exclusion filter: $(wc -l < "$FILE_LIST") file(s) remaining."
            fi
            if [ ! -s "$FILE_LIST" ]; then
              echo "All changed files are in excluded paths."
              echo "skip=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Install flawfinder
        if: steps.changed.outputs.skip == 'false'
        run: |
          python3 -m pip install --user flawfinder 2>/dev/null || \
            (sudo apt-get update -qq && sudo apt-get install -y -qq python3-pip && python3 -m pip install --user flawfinder)
          export PATH="$HOME/.local/bin:$PATH"
          flawfinder --version

      - name: Run flawfinder
        if: steps.changed.outputs.skip == 'false'
        id: flawfinder
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          FILES=$(cat /tmp/changed_cpp_files.txt | tr '\n' ' ')

          # Generate SARIF and human-readable output
          flawfinder --minlevel=${{ inputs.flawfinder_min_level }} --sarif --dataonly $FILES > flawfinder.sarif 2>/dev/null || true
          flawfinder --minlevel=${{ inputs.flawfinder_min_level }} --columns --context --dataonly $FILES > flawfinder.txt 2>&1 || true

          echo "::group::Flawfinder Results"
          cat flawfinder.txt
          echo "::endgroup::"

          # Count actual findings (lines matching "file:line:col:  [level]"), not advice/context lines
          HITS=$(grep -cE '^.+:[0-9]+:[0-9]+:' flawfinder.txt 2>/dev/null || true)
          [ -z "$HITS" ] && HITS=0
          echo "Flawfinder found ${HITS} potential issues (minlevel=${{ inputs.flawfinder_min_level }})"
          echo "hits=$HITS" >> $GITHUB_OUTPUT

          if [ "$HITS" -gt 0 ]; then
            echo "::error::Flawfinder found ${HITS} CWE issues. Suppress false positives with '// Flawfinder: ignore' or fix the findings."
            exit 1
          fi

      - name: Upload results
        if: always() && steps.changed.outputs.skip == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: flawfinder-results
          path: |
            flawfinder.sarif
            flawfinder.txt
          retention-days: 90

      - name: Upload SARIF
        if: always() && steps.changed.outputs.skip == 'false' && inputs.enable_sarif
        continue-on-error: true
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: flawfinder.sarif
          category: flawfinder

  sanitizer-tests:
    name: ASAN/UBSAN tests
    needs: [verify-toolchain]
    if: inputs.enable_sanitizers && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'sanitizers'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Prepare cache paths
        if: inputs.build_cache_key != ''
        id: cache-paths
        run: |
          {
            echo "paths<<EOF"
            echo "${{ inputs.build_cache_paths }}" | tr ' ' '\n'
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Restore build cache
        if: inputs.build_cache_key != ''
        uses: actions/cache@v5
        with:
          path: ${{ steps.cache-paths.outputs.paths }}
          key: ${{ inputs.build_cache_key }}-sanitizer
          restore-keys: |
            ${{ inputs.build_cache_key }}-sanitizer-
            ${{ inputs.build_cache_key }}-

      - name: Run sanitizer script
        if: inputs.sanitizer_script != ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}bash ${{ inputs.sanitizer_script }}"

      - name: Build with sanitizers (default flow)
        if: inputs.sanitizer_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.sanitizer_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.sanitizer_packages }}"
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              colcon build \
                --cmake-args \
                  -DCMAKE_BUILD_TYPE=Debug \
                  -DCMAKE_CXX_FLAGS='-fsanitize=address,undefined -fno-omit-frame-pointer -fno-sanitize-recover=all' \
                  -DCMAKE_C_FLAGS='-fsanitize=address,undefined -fno-omit-frame-pointer -fno-sanitize-recover=all' \
                  -DCMAKE_EXE_LINKER_FLAGS='-fsanitize=address,undefined' \
                  -DCMAKE_SHARED_LINKER_FLAGS='-fsanitize=address,undefined' \
                --event-handlers console_cohesion+ \
                --continue-on-error \
                $PACKAGES_ARG
            "

      - name: Run tests under sanitizers (default flow)
        if: inputs.sanitizer_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.sanitizer_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.sanitizer_packages }}"
          fi
          LSAN_SUPP=""
          if [ -n "${{ inputs.sanitizer_suppressions }}" ]; then
            LSAN_SUPP="suppressions=${{ inputs.source_mount }}/${{ inputs.sanitizer_suppressions }}"
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            -e ASAN_OPTIONS="halt_on_error=1:new_delete_type_mismatch=0:detect_leaks=1" \
            -e UBSAN_OPTIONS="halt_on_error=1:print_stacktrace=1" \
            -e LSAN_OPTIONS="$LSAN_SUPP" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              source install/local_setup.bash 2>/dev/null || true
              colcon test \
                --event-handlers console_cohesion+ \
                --return-code-on-test-failure \
                $PACKAGES_ARG
              colcon test-result --verbose
            "

  tsan-tests:
    name: TSAN tests
    needs: [verify-toolchain]
    if: inputs.enable_tsan && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'tsan'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Prepare cache paths
        if: inputs.build_cache_key != ''
        id: cache-paths
        run: |
          {
            echo "paths<<EOF"
            echo "${{ inputs.build_cache_paths }}" | tr ' ' '\n'
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Restore build cache
        if: inputs.build_cache_key != ''
        uses: actions/cache@v5
        with:
          path: ${{ steps.cache-paths.outputs.paths }}
          key: ${{ inputs.build_cache_key }}-tsan
          restore-keys: |
            ${{ inputs.build_cache_key }}-tsan-
            ${{ inputs.build_cache_key }}-

      - name: Run TSAN script
        if: inputs.tsan_script != ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          docker run --rm \
            --security-opt seccomp=unconfined \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}bash ${{ inputs.tsan_script }}"

      - name: Build with TSAN (default flow)
        if: inputs.tsan_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.tsan_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.tsan_packages }}"
          fi
          docker run --rm \
            --security-opt seccomp=unconfined \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              colcon build \
                --cmake-args \
                  -DCMAKE_BUILD_TYPE=Debug \
                  -DCMAKE_CXX_FLAGS='-fsanitize=thread -fno-omit-frame-pointer -fno-sanitize-recover=all' \
                  -DCMAKE_C_FLAGS='-fsanitize=thread -fno-omit-frame-pointer -fno-sanitize-recover=all' \
                  -DCMAKE_EXE_LINKER_FLAGS='-fsanitize=thread' \
                  -DCMAKE_SHARED_LINKER_FLAGS='-fsanitize=thread' \
                --event-handlers console_cohesion+ \
                --continue-on-error \
                $PACKAGES_ARG
            "

      - name: Run tests under TSAN (default flow)
        if: inputs.tsan_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.tsan_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.tsan_packages }}"
          fi
          TSAN_SUPP=""
          if [ -n "${{ inputs.tsan_suppressions }}" ]; then
            TSAN_SUPP="suppressions=${{ inputs.source_mount }}/${{ inputs.tsan_suppressions }}"
          fi
          docker run --rm \
            --security-opt seccomp=unconfined \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            -e TSAN_OPTIONS="halt_on_error=1:second_deadlock_stack=1:$TSAN_SUPP" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              source install/local_setup.bash 2>/dev/null || true
              colcon test \
                --event-handlers console_cohesion+ \
                --return-code-on-test-failure \
                $PACKAGES_ARG
              colcon test-result --verbose
            "

  iwyu:
    name: IWYU
    needs: [verify-toolchain]
    if: inputs.enable_iwyu && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'iwyu'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Get changed C++ files
        id: changed
        run: |
          EXT_PATTERN="\.($(echo "${{ inputs.file_extensions }}" | tr ' ' '|'))$"
          FILES=$(git diff --name-only --diff-filter=ACMR origin/${{ inputs.base_ref || github.base_ref || 'main' }} -- | grep -E "$EXT_PATTERN" || true)
          if [ -z "$FILES" ]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "No C++ files changed."
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "$FILES" > /tmp/changed_cpp_files.txt
            echo "Found $(echo "$FILES" | wc -l) changed file(s)."
          fi

      - name: Filter excluded paths
        if: steps.changed.outputs.skip == 'false' && inputs.exclude_file != ''
        run: |
          EXCLUDE_FILE="${{ inputs.exclude_file }}"
          FILE_LIST="/tmp/changed_cpp_files.txt"
          if [ -f "$EXCLUDE_FILE" ] && [ -f "$FILE_LIST" ]; then
            PATTERNS=()
            while IFS= read -r line || [ -n "$line" ]; do
              line="${line%%#*}"; line="$(echo "$line" | xargs)"
              [ -z "$line" ] && continue
              PATTERNS+=("$line")
            done < "$EXCLUDE_FILE"
            if [ ${#PATTERNS[@]} -gt 0 ]; then
              TEMP=$(mktemp)
              while IFS= read -r fp || [ -n "$fp" ]; do
                [ -z "$fp" ] && continue
                excl=false
                for p in "${PATTERNS[@]}"; do
                  [[ "$fp" == "$p"* ]] && excl=true && break
                done
                [ "$excl" = false ] && echo "$fp"
              done < "$FILE_LIST" > "$TEMP"
              mv "$TEMP" "$FILE_LIST"
              echo "After exclusion filter: $(wc -l < "$FILE_LIST") file(s) remaining."
            fi
            if [ ! -s "$FILE_LIST" ]; then
              echo "All changed files are in excluded paths."
              echo "skip=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Prepare cache paths
        if: steps.changed.outputs.skip == 'false' && inputs.build_cache_key != ''
        id: cache-paths
        run: |
          {
            echo "paths<<EOF"
            echo "${{ inputs.build_cache_paths }}" | tr ' ' '\n'
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Restore build cache
        if: steps.changed.outputs.skip == 'false' && inputs.build_cache_key != ''
        uses: actions/cache@v5
        with:
          path: ${{ steps.cache-paths.outputs.paths }}
          key: ${{ inputs.build_cache_key }}
          restore-keys: |
            ${{ inputs.build_cache_key }}-

      - name: Run IWYU script
        if: steps.changed.outputs.skip == 'false' && inputs.iwyu_script != ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          docker run --rm \
            -e GITHUB_BASE_REF=${{ inputs.base_ref || github.base_ref || 'main' }} \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}bash ${{ inputs.iwyu_script }}"

      - name: Run IWYU default flow
        if: steps.changed.outputs.skip == 'false' && inputs.iwyu_script == ''
        id: iwyu
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi

          MAPPING_ARG=""
          if [ -n "${{ inputs.iwyu_mapping_file }}" ]; then
            MAPPING_ARG="-Xiwyu --mapping_file=${{ inputs.source_mount }}/${{ inputs.iwyu_mapping_file }}"
          fi

          cp /tmp/changed_cpp_files.txt changed_files.txt

          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              if ! command -v include-what-you-use &>/dev/null; then
                echo 'Installing include-what-you-use...'
                apt-get update -qq && apt-get install -y -qq iwyu 2>/dev/null || {
                  echo 'ERROR: Could not install iwyu'
                  exit 1
                }
              fi
              echo \"IWYU version: \$(include-what-you-use --version 2>&1 | head -1 || true)\"
              cat changed_files.txt | while IFS= read -r file; do
                [ -z \"\$file\" ] && continue
                [ -f \"\$file\" ] || continue
                echo \"  IWYU: \$file\"
                include-what-you-use -p ${{ inputs.compile_commands_path }} $MAPPING_ARG \"\$file\" 2>&1 || true
              done
            " | tee /tmp/iwyu_output.txt || true

          ADD_COUNT=$(grep -c "should add these lines:" /tmp/iwyu_output.txt 2>/dev/null || true)
          REM_COUNT=$(grep -c "should remove these lines:" /tmp/iwyu_output.txt 2>/dev/null || true)
          echo ""
          echo "=== IWYU Summary ==="
          echo "Files with missing includes: $ADD_COUNT"
          echo "Files with unnecessary includes: $REM_COUNT"
          echo "NOTE: This job is non-blocking (report-only)."

  coverage:
    name: Test Coverage
    needs: [verify-toolchain]
    if: inputs.enable_coverage && (inputs.select_jobs == 'all' || contains(inputs.select_jobs, 'coverage'))
    runs-on: ${{ fromJSON(inputs.runner) }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: ${{ inputs.checkout_submodules }}

      - name: Login to GitHub Container Registry
        if: inputs.docker_image != ''
        run: echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Prepare cache paths
        if: inputs.build_cache_key != ''
        id: cache-paths
        run: |
          {
            echo "paths<<EOF"
            echo "${{ inputs.build_cache_paths }}" | tr ' ' '\n'
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Restore build cache
        if: inputs.build_cache_key != ''
        uses: actions/cache@v5
        with:
          path: ${{ steps.cache-paths.outputs.paths }}
          key: ${{ inputs.build_cache_key }}-coverage
          restore-keys: ${{ inputs.build_cache_key }}-coverage-

      - name: Run coverage script
        if: inputs.coverage_script != ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          docker run --rm \
            -e COVERAGE_THRESHOLD=${{ inputs.coverage_threshold }} \
            -e COVERAGE_DIFF_THRESHOLD=${{ inputs.coverage_diff_threshold }} \
            -e GITHUB_BASE_REF=${{ inputs.base_ref || github.base_ref || 'main' }} \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "${SETUP_CMD}bash ${{ inputs.coverage_script }}"

      - name: Build with coverage (default flow)
        if: inputs.coverage_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.coverage_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.coverage_packages }}"
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              apt-get update -qq && apt-get install -y -qq lcov 2>/dev/null || true
              colcon build \
                --cmake-args \
                  -DCMAKE_BUILD_TYPE=Debug \
                  \"-DCMAKE_CXX_FLAGS=--coverage -fno-omit-frame-pointer\" \
                  \"-DCMAKE_C_FLAGS=--coverage -fno-omit-frame-pointer\" \
                  \"-DCMAKE_EXE_LINKER_FLAGS=--coverage\" \
                  \"-DCMAKE_SHARED_LINKER_FLAGS=--coverage\" \
                --event-handlers console_cohesion+ \
                --continue-on-error \
                $PACKAGES_ARG
            "

      - name: Run tests and collect coverage (default flow)
        if: inputs.coverage_script == ''
        run: |
          SETUP_CMD=""
          if [ -n "${{ inputs.source_setup }}" ]; then
            SETUP_CMD="${{ inputs.source_setup }} && "
          fi
          PACKAGES_ARG=""
          if [ -n "${{ inputs.coverage_packages }}" ]; then
            PACKAGES_ARG="--packages-select ${{ inputs.coverage_packages }}"
          fi
          docker run --rm \
            -v "${{ github.workspace }}:${{ inputs.source_mount }}" \
            -w "${{ inputs.source_mount }}" \
            "${{ inputs.docker_image }}" \
            bash -c "
              ${SETUP_CMD}
              source install/local_setup.bash 2>/dev/null || true
              lcov --zerocounters --directory build/ 2>/dev/null || true
              lcov --capture --initial --directory build/ --output-file coverage_base.info --ignore-errors mismatch 2>/dev/null || true
              colcon test \
                --event-handlers console_cohesion+ \
                --return-code-on-test-failure \
                $PACKAGES_ARG || true
              lcov --capture --directory build/ --output-file coverage_test.info --ignore-errors mismatch
              lcov --add-tracefile coverage_base.info --add-tracefile coverage_test.info --output-file coverage_combined.info --ignore-errors mismatch 2>/dev/null || \
                cp coverage_test.info coverage_combined.info
              lcov --remove coverage_combined.info '/opt/*' '/usr/*' 'build/_deps/*' '*/test/*' --output-file coverage.info --ignore-errors mismatch
              genhtml coverage.info --output-directory coverage_html --ignore-errors mismatch 2>/dev/null || true
              lcov --summary coverage.info --ignore-errors mismatch 2>&1 | tee coverage-summary.txt
            "

      - name: Check coverage threshold (default flow)
        if: inputs.coverage_script == '' && inputs.coverage_threshold != '0'
        run: |
          if [ ! -f coverage-summary.txt ]; then
            echo "No coverage summary found"
            exit 1
          fi
          OVERALL=$(grep -oP '[\d.]+%' coverage-summary.txt | head -1 | tr -d '%')
          echo "Overall line coverage: ${OVERALL}%"
          if [ -n "$OVERALL" ] && [ "$(echo "$OVERALL < ${{ inputs.coverage_threshold }}" | bc -l)" -eq 1 ]; then
            echo "FAIL: Coverage ${OVERALL}% is below threshold ${{ inputs.coverage_threshold }}%"
            exit 1
          fi
          echo "PASS: Coverage ${OVERALL}% meets threshold ${{ inputs.coverage_threshold }}%"

      - name: Run diff-cover (default flow)
        if: inputs.coverage_script == '' && inputs.coverage_diff_threshold != '0'
        run: |
          pip install diff-cover --quiet
          diff-cover coverage.info \
            --compare-branch="origin/${{ inputs.base_ref || github.base_ref || 'main' }}" \
            --fail-under=${{ inputs.coverage_diff_threshold }} \
            --markdown-report diff-cover.md \
            2>&1 | tee diff-cover-output.txt

      - name: Upload coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            coverage.info
            coverage-summary.txt
            coverage_html/
            diff-cover.md

  summary:
    name: Post Summary
    runs-on: ${{ fromJSON(inputs.runner) }}
    needs: [verify-toolchain, clang-tidy, cppcheck, clang-format, doctest-enforce, file-naming, cout-ban, new-delete-ban, flawfinder, sanitizer-tests, tsan-tests, iwyu, coverage]
    if: always() && github.event_name == 'pull_request'
    steps:
      - name: Post or update PR comment
        uses: actions/github-script@v7
        with:
          script: |
            const marker = '<!-- cpp-quality-report -->';
            const tidy = '${{ needs.clang-tidy.result }}';
            const check = '${{ needs.cppcheck.result }}';
            const format = '${{ needs.clang-format.result }}';
            const doctest = '${{ needs.doctest-enforce.result }}';
            const naming = '${{ needs.file-naming.result }}';
            const coutBan = '${{ needs.cout-ban.result }}';
            const newBan = '${{ needs.new-delete-ban.result }}';
            const flaw = '${{ needs.flawfinder.result }}';
            const sanitizer = '${{ needs.sanitizer-tests.result }}';
            const tsan = '${{ needs.tsan-tests.result }}';
            const iwyu = '${{ needs.iwyu.result }}';
            const coverage = '${{ needs.coverage.result }}';

            const icon = (r) => {
              if (r === 'success') return '✅';
              if (r === 'skipped') return '⏭️';
              if (r === 'failure') return '❌';
              return '⚠️';
            };

            let body = marker + '\n## C++ Quality Scoreboard\n\n';
            body += '| Check | Result |\n|:------|:------:|\n';
            body += `| clang-tidy | ${icon(tidy)} ${tidy === 'success' || tidy === 'skipped' ? 'clean' : 'issues found'} |\n`;
            body += `| cppcheck | ${icon(check)} ${check === 'success' || check === 'skipped' ? 'clean' : 'issues found'} |\n`;
            if (format && format !== 'skipped') {
              body += `| clang-format | ${icon(format)} ${format === 'success' ? 'clean' : 'formatting issues'} |\n`;
            }
            if (doctest && doctest !== 'skipped') {
              body += `| doctest enforcement | ${icon(doctest)} ${doctest === 'success' ? 'clean' : 'banned framework found'} |\n`;
            }
            if (naming && naming !== 'skipped') {
              body += `| file naming | ${icon(naming)} ${naming === 'success' ? 'clean' : 'naming violations'} |\n`;
            }
            if (coutBan && coutBan !== 'skipped') {
              body += `| cout/printf ban | ${icon(coutBan)} ${coutBan === 'success' ? 'clean' : 'banned I/O found'} |\n`;
            }
            if (newBan && newBan !== 'skipped') {
              body += `| new/delete ban | ${icon(newBan)} ${newBan === 'success' ? 'clean' : 'raw new/delete found'} |\n`;
            }
            if (flaw && flaw !== 'skipped') {
              body += `| flawfinder | ${icon(flaw)} ${flaw === 'success' ? 'clean' : 'CWE findings'} |\n`;
            }
            if (sanitizer && sanitizer !== 'skipped') {
              body += `| ASAN/UBSAN | ${icon(sanitizer)} ${sanitizer === 'success' ? 'clean' : 'sanitizer errors'} |\n`;
            }
            if (tsan && tsan !== 'skipped') {
              body += `| TSAN | ${icon(tsan)} ${tsan === 'success' ? 'clean' : 'thread-safety errors'} |\n`;
            }
            if (iwyu && iwyu !== 'skipped') {
              body += `| IWYU | ${icon(iwyu)} ${iwyu === 'success' ? 'clean' : 'unnecessary includes found'} |\n`;
            }
            if (coverage && coverage !== 'skipped') {
              body += `| Coverage | ${icon(coverage)} ${coverage === 'success' ? 'thresholds met' : 'below threshold'} |\n`;
            }
            body += '\n---\n<sub>Powered by <a href="https://github.com/PavelGuzenfeld/standard">standard</a> · Only changed files checked</sub>';

            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });
            const existing = comments.find(c => c.body.includes(marker));

            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body: body,
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body,
              });
            }
